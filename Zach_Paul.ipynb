{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I imported in a dataset provided by IMDB's interface. Scraping the data from their website turned out to be unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\anaconda37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "D:\\Python\\anaconda37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.00 MiB for an array with shape (131072,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0df238a8b2fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtitle_basics_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'zippedData/title.basics.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtitle_crew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'zippedData/title.crew.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtitle_principals_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'zippedData/title.principals.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtitle_ratings_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'zippedData/title.ratings.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\anaconda37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\anaconda37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\anaconda37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\anaconda37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._try_int64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.00 MiB for an array with shape (131072,) and data type int64"
     ]
    }
   ],
   "source": [
    "name_basics_df = pd.read_csv('zippedData/name.basics.tsv', sep='\\t')\n",
    "title_akas_df = pd.read_csv('zippedData/title.akas.tsv', sep='\\t')\n",
    "title_basics_df = pd.read_csv('zippedData/title.basics.tsv', sep='\\t')\n",
    "title_crew_df = pd.read_csv('zippedData/title.crew.tsv', sep='\\t')\n",
    "title_principals_df = pd.read_csv('zippedData/title.principals.tsv', sep='\\t')\n",
    "title_ratings_df = pd.read_csv('zippedData/title.ratings.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This database is still missing the cost to make movie and the profit. We found a database containing the production costs, worldwide and domestic gross income. This information is not given to us in a file unfortunately like the previous dataset was, so we will have to employ some datascraping to pull this data off the website. We are grabbing our data from https://www.the-numbers.com/movie/budgets/all\n",
    "I defined 2 functions to ease the load since I need to run a separate iteration of this script in order to catch the first page due to it having a unique url. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Takes in the URL as an argument, and returns the chart that the movies are in.'''\n",
    "def html_parse(url):\n",
    "    html_page = requests.get(url, timeout=5)\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    chart = soup.find(id = 'page_filling_chart')\n",
    "    movie_container = chart.findAll('tr') #grabs all movie entries on the page and puts into a list\n",
    "    return movie_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Takes in the row containing the movie title, profits, release date, and costs and returns a list of those.'''\n",
    "def movie_extract(data_container):\n",
    "        release_date = data_container[1].text #release date\n",
    "        movie_name = data_container[2].text #name of movie\n",
    "        prod_budget = data_container[3].get_text(strip=True) #production budget\n",
    "        gross_dom = data_container[4].get_text(strip=True) #gross domestic \n",
    "        gross_world = data_container[5].get_text(strip=True) #gross worldwide\n",
    "        \n",
    "        return [release_date, movie_name, prod_budget, gross_dom, gross_world]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the initial run of the function due to the URL being unique for the very first page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Release_Date', 'Movie_Name', 'Production_Budget', 'Gross_Domestic', 'Gross_Worldwide'])\n",
    "url = \"https://www.the-numbers.com/movie/budgets/all\"\n",
    "movie_container = html_parse(url)\n",
    "\n",
    "#for loop here to iterate through the list of movies in movie_container\n",
    "for u in range(1,101): #this'll break on the last page, find better way to do it\n",
    "    data_container = movie_container[u].findAll('td')\n",
    "\n",
    "    data_series = movie_extract(data_container)\n",
    "    \n",
    "    a_series = pd.Series(data_series, index = df.columns)\n",
    "    df = df.append(a_series, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterates through all the pages utilizing URL hacking to find all of the pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,61): #change 4 to 61 for all\n",
    "    url = \"https://www.the-numbers.com/movie/budgets/all/{}01\".format(i)\n",
    "    movie_container = html_parse(url)\n",
    "\n",
    "    #for loop here to iterate through the list of movies in movie_container\n",
    "    for u in range(1,101): \n",
    "        if i == 60 and u == 44:\n",
    "            break\n",
    "        data_container = movie_container[u].findAll('td')\n",
    "\n",
    "        data_series = movie_extract(data_container)\n",
    "        \n",
    "        a_series = pd.Series(data_series, index = df.columns)\n",
    "        df = df.append(a_series, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('zippedData/movieMoney.csv') #saving it to a CSV so I don't have to scrape everytime I want to look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release_Date</th>\n",
       "      <th>Movie_Name</th>\n",
       "      <th>Production_Budget</th>\n",
       "      <th>Gross_Domestic</th>\n",
       "      <th>Gross_Worldwide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apr 23, 2019</td>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>$400,000,000</td>\n",
       "      <td>$858,373,000</td>\n",
       "      <td>$2,797,800,564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May 20, 2011</td>\n",
       "      <td>Pirates of the Caribbean: On Stranger Tides</td>\n",
       "      <td>$379,000,000</td>\n",
       "      <td>$241,063,875</td>\n",
       "      <td>$1,045,663,875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apr 22, 2015</td>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>$365,000,000</td>\n",
       "      <td>$459,005,868</td>\n",
       "      <td>$1,396,099,202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dec 16, 2015</td>\n",
       "      <td>Star Wars Ep. VII: The Force Awakens</td>\n",
       "      <td>$306,000,000</td>\n",
       "      <td>$936,662,225</td>\n",
       "      <td>$2,065,478,084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apr 25, 2018</td>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>$300,000,000</td>\n",
       "      <td>$678,815,482</td>\n",
       "      <td>$2,048,359,754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Red 11</td>\n",
       "      <td>$7,000</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>Apr 2, 1999</td>\n",
       "      <td>Following</td>\n",
       "      <td>$6,000</td>\n",
       "      <td>$48,482</td>\n",
       "      <td>$240,495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5940</th>\n",
       "      <td>Jul 13, 2005</td>\n",
       "      <td>Return to the Land of Wonders</td>\n",
       "      <td>$5,000</td>\n",
       "      <td>$1,338</td>\n",
       "      <td>$1,338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>Sep 29, 2015</td>\n",
       "      <td>A Plague So Pleasant</td>\n",
       "      <td>$1,400</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5942</th>\n",
       "      <td>Aug 5, 2005</td>\n",
       "      <td>My Date With Drew</td>\n",
       "      <td>$1,100</td>\n",
       "      <td>$181,041</td>\n",
       "      <td>$181,041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5943 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Release_Date                                   Movie_Name  \\\n",
       "0     Apr 23, 2019                            Avengers: Endgame   \n",
       "1     May 20, 2011  Pirates of the Caribbean: On Stranger Tides   \n",
       "2     Apr 22, 2015                      Avengers: Age of Ultron   \n",
       "3     Dec 16, 2015         Star Wars Ep. VII: The Force Awakens   \n",
       "4     Apr 25, 2018                       Avengers: Infinity War   \n",
       "...            ...                                          ...   \n",
       "5938       Unknown                                       Red 11   \n",
       "5939   Apr 2, 1999                                    Following   \n",
       "5940  Jul 13, 2005                Return to the Land of Wonders   \n",
       "5941  Sep 29, 2015                         A Plague So Pleasant   \n",
       "5942   Aug 5, 2005                            My Date With Drew   \n",
       "\n",
       "     Production_Budget Gross_Domestic Gross_Worldwide  \n",
       "0         $400,000,000   $858,373,000  $2,797,800,564  \n",
       "1         $379,000,000   $241,063,875  $1,045,663,875  \n",
       "2         $365,000,000   $459,005,868  $1,396,099,202  \n",
       "3         $306,000,000   $936,662,225  $2,065,478,084  \n",
       "4         $300,000,000   $678,815,482  $2,048,359,754  \n",
       "...                ...            ...             ...  \n",
       "5938            $7,000             $0              $0  \n",
       "5939            $6,000        $48,482        $240,495  \n",
       "5940            $5,000         $1,338          $1,338  \n",
       "5941            $1,400             $0              $0  \n",
       "5942            $1,100       $181,041        $181,041  \n",
       "\n",
       "[5943 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things we want to look at.\n",
    "1) Day of release affects profit\n",
    "2) Genre of movie affects profit\n",
    "3) Actors in movie affects profit\n",
    "4) Season of release affects profit\n",
    "5) international sales\n",
    "6) average number of movies to make\n",
    "7) number of reviews and gross #scatter plot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1) Genre of movie affects profit\n",
    "    a) season for the genre to be released\n",
    "    boxplot\n",
    "    b) What genres succeed internationally\n",
    "    boxplot x- genres, y profit\n",
    "2) Number of reviews and profit\n",
    "    a)scatter plot, x is number of votes,y is profit #see if number of views is what matters\n",
    "        i) color code the review rating, 10-8 green, 7-5 yellow etc...\n",
    "    b) scatter plot, x is number of votes, y is production cost #see if higher production costs get more views\n",
    "3) How does the number of movies created by a studio affect the average profit\n",
    "    a)do franchises do better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting to look at and scrub the data. The first step is going to be converting the datatypes into a usable form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('zippedData/movieMoney.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Release_Date         datetime64[ns]\n",
       "Movie_Name                   string\n",
       "Production_Budget             int32\n",
       "Gross_Domestic                int32\n",
       "Gross_Worldwide               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release_Date</th>\n",
       "      <th>Movie_Name</th>\n",
       "      <th>Production_Budget</th>\n",
       "      <th>Gross_Domestic</th>\n",
       "      <th>Gross_Worldwide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>2022-12-16</td>\n",
       "      <td>Heaven and Hell</td>\n",
       "      <td>40000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>355</td>\n",
       "      <td>75000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Moonfall</td>\n",
       "      <td>150000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>Top Gun: Maverick</td>\n",
       "      <td>140000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>No Time to Die</td>\n",
       "      <td>250000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Release_Date         Movie_Name  Production_Budget  Gross_Domestic  \\\n",
       "1502   2022-12-16    Heaven and Hell           40000000               0   \n",
       "602    2021-01-15                355           75000000               0   \n",
       "108    2021-01-01           Moonfall          150000000               0   \n",
       "133    2020-12-23  Top Gun: Maverick          140000000               0   \n",
       "20     2020-11-12     No Time to Die          250000000               0   \n",
       "\n",
       "      Gross_Worldwide  \n",
       "1502                0  \n",
       "602                 0  \n",
       "108                 0  \n",
       "133                 0  \n",
       "20                  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Movie_Name'] = df['Movie_Name'].astype('string')\n",
    "\n",
    "df['Release_Date'] = pd.to_datetime(df['Release_Date'], errors='coerce')\n",
    "\n",
    "df['Production_Budget'] = df['Production_Budget'].str.replace('$', '')\n",
    "df['Production_Budget'] = df['Production_Budget'].str.replace(',', '')\n",
    "df['Production_Budget'] = df['Production_Budget'].astype(int)\n",
    "\n",
    "df['Gross_Domestic'] = df['Gross_Domestic'].str.replace('$', '')\n",
    "df['Gross_Domestic'] = df['Gross_Domestic'].str.replace(',', '')\n",
    "df['Gross_Domestic'] = df['Gross_Domestic'].astype(int)\n",
    "\n",
    "df['Gross_Worldwide'] = df['Gross_Worldwide'].str.replace('$', '')\n",
    "df['Gross_Worldwide'] = df['Gross_Worldwide'].str.replace(',', '')\n",
    "df['Gross_Worldwide'] = df['Gross_Worldwide'].astype('int64')\n",
    "\n",
    "df.sort_values('Release_Date', inplace=True, ascending=False) #sort by release date, most recent on bottom\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is to remove the films from the dataframe that haven't happened yet. The next step is to count the number of films that have no budget or not profit to see if they can be removed from the dataset without any problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to go through the IMDB dataset to remove data that we don't have profit information for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are loading in the dataset that we will be comparing the dataframe we have money information from. We're going to go ahead and convert the datatypes to their usable forms while we're doing this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_basics_df = pd.read_csv('zippedData/title.basics.tsv', sep='\\t')\n",
    "title_basics_list = list(title_basics_df.columns)\n",
    "unwanted_col = ['isAdult', 'startYear', 'endYear', 'runtimeMinutes']\n",
    "title_basics_list = [ele for ele in title_basics_list if ele not in unwanted_col] \n",
    "for col in title_basics_list:\n",
    "    title_basics_df[col] = title_basics_df[col].astype('string')\n",
    "title_basics_df.drop(title_basics_df[title_basics_df['titleType'] != 'movie'].index, inplace=True) #drop any rows that aren't movies\n",
    "title_basics_df['startYear'] = pd.to_datetime(title_basics_df['startYear'], errors='coerce')\n",
    "title_basics_df['endYear'] = pd.to_datetime(title_basics_df['endYear'], errors='coerce')\n",
    "title_basics_df['runtimeMinutes'].replace(to_replace='\\\\N', value='0', inplace=True)\n",
    "title_basics_df['runtimeMinutes'] = title_basics_df['runtimeMinutes'].astype('int', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list = list(df['Movie_Name'].unique()) #create a list of the movie titles we have money information for\n",
    "title_basics_df.drop(title_basics_df[title_basics_df['titleType'] != 'movie'].index, inplace=True) #drop any rows that are not movies\n",
    "title_basics_df = title_basics_df[title_basics_df['primaryTitle'].isin(movie_list)] #only keep movies we have money information for\n",
    "movie_list = list(title_basics_df['tconst'].unique()) #making the new list of movie names with IMDB uid\n",
    "title_basics_df.to_csv('zippedData/title_basics_pared.csv')\n",
    "title_basics_df.head() #preview what we got\n",
    "title_basics_df = None #clear the variable for memory, was having memory issues and I have a lot of DF to go through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataframe that only contains movies we have profit information for. We can now use the unique identifier for movies titles in IMDB's database to continue to pare down the remaining dataframes that we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_crew_df = pd.read_csv('zippedData/title.crew.tsv', sep='\\t')\n",
    "title_crew_df = title_crew_df[title_crew_df['tconst'].isin(movie_list)] #only keep movies we have money information for\n",
    "title_crew_df.to_csv('zippedData/title_crew_pared.csv')\n",
    "title_crew_df.head() #preview what we got\n",
    "title_crew_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\anaconda37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "title_akas_df = pd.read_csv('zippedData/title.akas.tsv', sep='\\t')\n",
    "title_akas_df = title_akas_df[title_akas_df['titleId'].isin(movie_list)] #only keep movies we have money information for\n",
    "title_akas_df.to_csv('zippedData/title_akas_pared.csv')\n",
    "title_akas_df.head() #preview what we got\n",
    "title_akas_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title_principals_df = pd.read_csv('zippedData/title.principals.tsv', sep='\\t')\n",
    "iter_csv = pd.read_csv('zippedData/title.principals.tsv', sep='\\t', iterator=True, chunksize=10000)\n",
    "title_principals_df = pd.concat([chunk[chunk['tconst'].isin(movie_list)] for chunk in iter_csv])\n",
    "title_principals_df.to_csv('zippedData/title_principals_pared.csv')\n",
    "title_principals_df.head() #preview what we got\n",
    "title_principals_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ratings_df = pd.read_csv('zippedData/title.ratings.tsv', sep='\\t')\n",
    "title_ratings_df = title_ratings_df[title_ratings_df['tconst'].isin(movie_list)] #only keep movies we have money information for\n",
    "title_ratings_df.to_csv('zippedData/title_ratings_pared.csv')\n",
    "title_ratings_df.head() #preview what we got\n",
    "title_ratings_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nconst                       string\n",
       "primaryName                  string\n",
       "birthYear            datetime64[ns]\n",
       "deathYear            datetime64[ns]\n",
       "primaryProfession            string\n",
       "knownForTitles               string\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_basics_df = pd.read_csv('zippedData/name.basics.tsv', sep='\\t')\n",
    "name_basics_df['nconst'] = name_basics_df['nconst'].astype('string')\n",
    "name_basics_df['primaryName'] = name_basics_df['primaryName'].astype('string')\n",
    "name_basics_df['primaryProfession'] = name_basics_df['primaryProfession'].astype('string')\n",
    "name_basics_df['knownForTitles'] = name_basics_df['knownForTitles'].astype('string')\n",
    "name_basics_df['birthYear'] = pd.to_datetime(name_basics_df['birthYear'], errors='coerce')\n",
    "name_basics_df['deathYear'] = pd.to_datetime(name_basics_df['deathYear'], errors='coerce')\n",
    "name_basics_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_akas_df.drop(title_akas_df[title_akas_df['region'] != 'US'].index, inplace=True) #holding onto this code incase I want it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "titleId            string\n",
       "ordering            int64\n",
       "title              string\n",
       "region             string\n",
       "language           string\n",
       "types              string\n",
       "attributes         string\n",
       "isOriginalTitle     int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_akas_df = pd.read_csv('zippedData/title_akas_pared.csv', index_col=0)\n",
    "title_akas_df['isOriginalTitle'].replace(to_replace='\\\\N', value='1', inplace=True)\n",
    "title_akas_df['titleId'] = title_akas_df['titleId'].astype('string')\n",
    "title_akas_df['title'] = title_akas_df['title'].astype('string')\n",
    "title_akas_df['region'] = title_akas_df['region'].astype('string')\n",
    "title_akas_df['language'] = title_akas_df['language'].astype('string')\n",
    "title_akas_df['types'] = title_akas_df['types'].astype('string')\n",
    "title_akas_df['attributes'] = title_akas_df['attributes'].astype('string')\n",
    "title_akas_df['isOriginalTitle'] = title_akas_df['isOriginalTitle'].astype('int')\n",
    "title_akas_df['titleId'] = title_akas_df['titleId'].astype('string')\n",
    "title_akas_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_crew_df = pd.read_csv('zippedData/title_crew_pared.csv', index_col=0)\n",
    "title_crew_list = list(title_crew_df.columns)\n",
    "for col in title_crew_list:\n",
    "    title_crew_df[col] = title_crew_df[col].astype('string')\n",
    "title_crew_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_principals_df = pd.read_csv('zippedData/title_principals_pared.csv', index_col=0)\n",
    "title_principals_list = list(title_principals_df.columns)\n",
    "title_principals_list.remove('ordering')\n",
    "for col in title_principals_list:\n",
    "    title_principals_df[col] = title_principals_df[col].astype('string')\n",
    "title_principals_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ratings_df = pd.read_csv('zippedData/title_ratings_pared.csv', index_col=0)\n",
    "title_ratings_df['tconst'] = title_ratings_df['tconst'].astype('string')\n",
    "title_ratings_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've created all the dataframes that I need to use for the project. I now need to look through them and combine them in a meaningful way. A SQL database could work here, or a pivot table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_basics_df = pd.read_csv('zippedData/name.basics.tsv', sep='\\t')\n",
    "title_akas_df = pd.read_csv('zippedData/title.akas.tsv', sep='\\t')\n",
    "title_basics_df = pd.read_csv('zippedData/title.basics.tsv', sep='\\t')\n",
    "title_crew_df = pd.read_csv('zippedData/title.crew.tsv', sep='\\t')\n",
    "title_principals_df = pd.read_csv('zippedData/title.principals.tsv', sep='\\t')\n",
    "title_ratings_df = pd.read_csv('zippedData/title.ratings.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Genre of movie affects profit a) season for the genre to be released boxplot b) What genres succeed internationally boxplot x- genres, y profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='genre', y='profit', hue='international?', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='season', y='profit', hue='international?',\n",
    "            col='genre', col_wrap=6, data=df)\n",
    "#idk depends on the number of genres really"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot to answer question 2?\n",
    "Seems too easy.\n",
    "2) Number of reviews and profit a)scatter plot, x is number of votes,y is profit #see if number of views is what matters i) color code the review rating, 10-8 green, 7-5 yellow etc... b) scatter plot, x is number of votes, y is production cost #see if higher production costs get more views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='num_votes', y='profit', hue='rating', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='num_votes', y='prod_cost', hue='rating', data=df)\n",
    "#wait this should be reversed. Does higher production cost lead to higher  votes\n",
    "#not do movies with more votes have higher votes\n",
    "\n",
    "#instead of using hue as rating, could make x amount different plots\n",
    "#separating the ratings into the same number of groups\n",
    "#sns.lmplot(x='num_vote', y='prod_cost', col='rating', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) How does the number of movies created by a studio affect the average profit a)do franchises do better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need the dataset to actually do this...\n",
    "idk this seems like too few plots, or not ambitious enough. We're only going to have like 15 plots total at this rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='num_movies_inyear', y='avg_profit', hue='franchise?', data=df)\n",
    "#this question is going to be closer to\n",
    "#for each studio, group them by the number of films that they put out in a year\n",
    "#and then determine what the average profit is for each group\n",
    "#depending on the number of groups, may need to bin them.\n",
    "#then, subdivide those groups into films that are part of franchises\n",
    "#and those that are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
